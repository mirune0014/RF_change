# ランダムフォレスト実装プロジェクト

このプロジェクトは、決定木とランダムフォレストのアルゴリズムを基礎から実装したものです。
少数クラスに対する重み付きサンプリングなど、クラス不均衡に対応する機能も実装しています。

## プロジェクト構成

```
my_random_forest_project/
├── decision_tree.py     # 決定木の実装
├── random_forest.py     # ランダムフォレストの実装
└── main.py             # 実行用スクリプト
```

## ファイルの詳細

### decision_tree.py

決定木アルゴリズムの基本実装を含むファイルです。

#### クラス: SimpleDecisionTree

- **メソッド**
  - `__init__(max_depth=None, min_samples_split=2)`: 決定木の初期化
    - `max_depth`: 木の最大深さ（Noneの場合は制限なし）
    - `min_samples_split`: 分割に必要な最小サンプル数
  
  - `fit(X, y)`: モデルの学習
    - `X`: トレーニングデータの特徴量
    - `y`: トレーニングデータのターゲット値
  
  - `_split_node(X, y, depth)`: ノードの分割（内部メソッド）
    - 再帰的にノードを分割し、決定木を構築
  
  - `predict(X)`: 予測の実行
    - 新しいデータに対する予測を行う

### random_forest.py

ランダムフォレストアルゴリズムの実装を含むファイルです。

#### クラス: SimpleRandomForest

- **メソッド**
  - `__init__(n_estimators=10, max_depth=None, min_samples_split=2)`: 
    - `n_estimators`: 決定木の数
    - `max_depth`: 各決定木の最大深さ
    - `min_samples_split`: 分割に必要な最小サンプル数
  
  - `fit(X, y)`: モデルの学習
    - 特徴:
      - 少数クラスに2倍の重みを設定したブートストラップサンプリング
      - 特徴量のランダムサンプリング（特徴量数の平方根を使用）
  
  - `predict(X)`: アンサンブル予測
    - 全ての決定木の予測結果を用いた多数決による予測

### main.py

モデルの実行と評価用のスクリプトです。

- **機能**
  - irisデータセットの読み込みと前処理
  - データの学習用・テスト用への分割（8:2）
  - モデルの学習と評価
  - 結果の表示
    - 正解率の計算
    - クラスごとの予測数の表示

## 使用方法

1. モデルの実行:
```python
python main.py
```

2. 期待される出力:
```
モデルの学習を開始します...
テストデータで予測を行います...

結果:
正解率: X.XXXX

クラスごとの予測数:
クラス 0: XX個
クラス 1: XX個
クラス 2: XX個
```

## 実装の改善と性能変化

### 1. 基本実装（Initial Implementation）
- シンプルな決定木とランダムフォレストの実装
- 特徴:
  - 基本的なノード分割
  - 単純な予測メソッド
- 結果:
  - 予測がほぼ単一のクラスに偏る問題
  - 正解率: 約0.37

### 2. 重み付きGini不純度の導入
- 実装の改善:
  - `_weighted_gini_index`関数の追加
  - サンプルの重みを考慮した分割基準
  - 少数クラスに対する2倍の重み付け
- 理論的改善:
  - クラス不均衡への対応
  - より公平な分割基準の実現

### 3. 特徴量サンプリングの改善
- 実装の改善:
  - 各決定木の特徴量インデックスの保存
  - 予測時の特徴量の一貫性確保
  - サンプリング数の最小値（1）設定
- 結果:
  - 正解率: 0.9667（約60%の精度向上）
  - クラス予測分布の改善:
    - クラス0: 10個
    - クラス1: 8個
    - クラス2: 12個

### 4. OOBスコアを用いた加重多数決の導入
- 実装の改善:
  - Out-of-Bag (OOB)サンプルを使用した各決定木の性能評価
  - F1スコアに基づく決定木の重み付け
  - 予測時の加重多数決による投票

- 性能評価結果:
  - 正解率: 0.9667
  - マクロ平均F1スコア: 0.9659
  - クラスごとの詳細性能:
    ```
    クラス0: Precision=1.00, Recall=1.00, F1=1.00
    クラス1: Precision=1.00, Recall=0.89, F1=0.94
    クラス2: Precision=0.92, Recall=1.00, F1=0.96
    ```

### 改善の効果
1. 予測精度の向上過程
   - 初期実装: 正解率 0.37（単一クラスに偏り）
   - 重み付きGini導入後: 正解率 0.97
   - 加重多数決導入後: 正解率 0.97, F1スコア 0.97

2. クラスバランスの改善
   - 初期: 単一クラスへの偏り（クラス2のみ）
   - 中間: 全クラスへの分散（基本的なバランス）
   - 最終: クラスごとの高精度な予測（F1スコア0.94以上）

3. モデルの堅牢性
   - 特徴量選択の一貫性確保
   - OOBスコアによる木の品質評価
   - 少数クラスの高精度な識別
   - クラスごとの詳細な性能指標

4. アルゴリズムの改善ポイント
   - 重み付きGini不純度による公平な分割
   - OOBサンプルを活用した性能評価
   - 各決定木の信頼性を考慮した投票

## 拡張可能な機能

- ブートストラップサンプリングのon/off切り替え
- 特徴量サンプリング数のカスタマイズ
- 情報利得や不純度の計算方法の変更
- 木の可視化機能の追加
