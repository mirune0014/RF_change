# ランダムフォレスト実装プロジェクト

このプロジェクトは、決定木とランダムフォレストのアルゴリズムを基礎から実装したものです。
少数クラスに対する重み付きサンプリングなど、クラス不均衡に対応する機能も実装しています。

## プロジェクト構成

```
my_random_forest_project/
├── decision_tree.py     # 決定木の実装
├── random_forest.py     # ランダムフォレストの実装
└── main.py             # 実行用スクリプト
```

## ファイルの詳細

### decision_tree.py

決定木アルゴリズムの基本実装を含むファイルです。

#### クラス: SimpleDecisionTree

- **メソッド**
  - `__init__(max_depth=None, min_samples_split=2)`: 決定木の初期化
    - `max_depth`: 木の最大深さ（Noneの場合は制限なし）
    - `min_samples_split`: 分割に必要な最小サンプル数
  
  - `fit(X, y)`: モデルの学習
    - `X`: トレーニングデータの特徴量
    - `y`: トレーニングデータのターゲット値
  
  - `_split_node(X, y, depth)`: ノードの分割（内部メソッド）
    - 再帰的にノードを分割し、決定木を構築
  
  - `predict(X)`: 予測の実行
    - 新しいデータに対する予測を行う

### random_forest.py

ランダムフォレストアルゴリズムの実装を含むファイルです。

#### クラス: SimpleRandomForest

- **メソッド**
  - `__init__(n_estimators=10, max_depth=None, min_samples_split=2)`: 
    - `n_estimators`: 決定木の数
    - `max_depth`: 各決定木の最大深さ
    - `min_samples_split`: 分割に必要な最小サンプル数
  
  - `fit(X, y)`: モデルの学習
    - 特徴:
      - 少数クラスに2倍の重みを設定したブートストラップサンプリング
      - 特徴量のランダムサンプリング（特徴量数の平方根を使用）
  
  - `predict(X)`: アンサンブル予測
    - 全ての決定木の予測結果を用いた多数決による予測

### main.py

モデルの実行と評価用のスクリプトです。

- **機能**
  - irisデータセットの読み込みと前処理
  - データの学習用・テスト用への分割（8:2）
  - モデルの学習と評価
  - 結果の表示
    - 正解率の計算
    - クラスごとの予測数の表示

## 使用方法

1. モデルの実行:
```python
python main.py
```

2. 期待される出力:
```
モデルの学習を開始します...
テストデータで予測を行います...

結果:
正解率: X.XXXX

クラスごとの予測数:
クラス 0: XX個
クラス 1: XX個
クラス 2: XX個
```

## 拡張可能な機能

- ブートストラップサンプリングのon/off切り替え
- 特徴量サンプリング数のカスタマイズ
- 情報利得や不純度の計算方法の変更
- 木の可視化機能の追加
